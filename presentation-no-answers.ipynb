{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afb2056c",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "This workbook will cover the basics of working with Pandas, a Python package commonly used as the fundamental building block to conduct data analysis and machine learning.\n",
    "\n",
    "[Download Data](https://www.kaggle.com/competitions/home-credit-default-risk/data?select=bureau.csv)\n",
    "\n",
    "First let's take a look at importing the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc92861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import package\n",
    "\n",
    "# TO DO: To see all the data, set Pandas to display the max number of columns within the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c0ddd3",
   "metadata": {},
   "source": [
    "There are several different data types in Pandas but we'll be taking a look at two: Series and DataFrame.\n",
    "\n",
    "A series is a one dimensional array with axis labels - think like a column in a table.\n",
    "\n",
    "A dataframe is a two dimensional object, which can hold tabular data - think of it as a table built with multiple series.\n",
    "\n",
    "These are the fundamental building blocks to work with your data. From here, we can import our data and start to take a look at these different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf82199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import the data from the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582155e9",
   "metadata": {},
   "source": [
    "Data comes in many different formats, but we will be working with .csv files in this workbook. Tabular data will work best with a Pandas dataframe. \n",
    "\n",
    "Now let's take a look at our data. There are a series of commands we will take a look at which will tell us about our data.\n",
    "\n",
    "Starting off with the ```head()```/```tail()``` function: the head() function allows you to view the first few rows of the dataframe while the tail() function allows you to view the last few rows. This is great to get a quick glimpse of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fa10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: use the head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab58021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: use the tail() function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7dd1d",
   "metadata": {},
   "source": [
    "The ```describe()``` function prints the summary statistics of numeric type columns, including count, mean, standard deviationm and the quartile values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b78b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: use the describe function - do you see anything interesting with the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee5af0",
   "metadata": {},
   "source": [
    "The ```info()``` method gives a quick way to look at the different data types and missing values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5023afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Use the info() function to identify the number of non-null values and \n",
    "# the data types for each column - do you see anything that stands out?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5d9cf",
   "metadata": {},
   "source": [
    "The ```shape``` command identifies the number of rows and columns in the dataframe in the following format (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cce616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: How many rows and columns are in the data frame?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fcfc63",
   "metadata": {},
   "source": [
    "Here, we use the ```isnull()``` function to identify the number of null values per each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc9b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: How many null values are there in each column?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a708dc",
   "metadata": {},
   "source": [
    "If you are searching for certain data, you search by column or by row.\n",
    "\n",
    "The following are the row functions: ```loc[]``` returns one or more specified rows based on the argument you give. Note ```loc[]``` is based on index label location where as ```iloc[]``` is based on integer location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05270da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Use the loc function to isolate the first row of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd12d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Now try isolating two columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe84bd",
   "metadata": {},
   "source": [
    "You can also use ```loc[rows, columns]``` and ```iloc[rows, columns]``` to isolate columnns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6921148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Try isolating the columns now to CODE_GENDER and NAME_CONTRACT_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a0dc8d",
   "metadata": {},
   "source": [
    "You can also isolate columns by simply calling the dataframe and the column title as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44350bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Try calling the columns without using the loc/iloc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f41069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Call three more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151ada0",
   "metadata": {},
   "source": [
    "You can also use Pandas to filter your dataframe to look at a specific subsection of the data and isolate the rows that match your specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Filter for all the females in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09314965",
   "metadata": {},
   "source": [
    "Combining the filtering with the ```loc``` function gives you more flexibility to narrow down your results and provide you with the results you want to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Use the loc function to isolate all the females who have taken out Revolving loans \n",
    "# and isolate the columns to CNT_CHILDREN the AMT_INCOME_TOTAL and AMT_CREDIT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2b999",
   "metadata": {},
   "source": [
    "# Data Transformation\n",
    "\n",
    "Now that we know the basics of working with Pandas dataframes, let's start working with the data. \n",
    "\n",
    "Before we do any analysis or machine learning, we want to be able to transform the data so that we can extract meaningful insights from otherwise \"dirty data\" (data that is incomplete, inconsistent, or inaccurate).\n",
    "\n",
    "In order for us to achieve a state where the data is ready to be analyzed we need to do the following:\n",
    "\n",
    "Clean: This means correcting inaccuracies, filling in missing values, and removing duplicates.\n",
    "\n",
    "Enrich: This means adding value to the dataset; this might mean merging with another data frame or calculating additional metrics from the raw data.\n",
    "\n",
    "Validate: This means validating the changes to see if the data is accurate and/or consistent after the data wrangling.\n",
    "\n",
    "After we accomplish these three steps, we move to the analysis.\n",
    "\n",
    "Now, let's start with the cleaning.\n",
    "\n",
    "## Cleaning\n",
    "\n",
    "When taking a look at your dataset you may see a value labeled as NaN - these are null values where data was not entered or provided. As we had seen earlier (```df.info()```), the data above is riddled with null values. Our first step is in addressing that. There are several ways to deal with missing data. Here are the main two:\n",
    "\n",
    "- Dropping missing values: Using the ```dropna()``` function, any row that has a NaN value will be dropped. Note that below, the amount of rows has significantly decreased when we drop NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d006e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Try using the dropna() function. Originally we had over 300,000 columns, now how many do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f82023c",
   "metadata": {},
   "source": [
    "- Replacing missing values: Instead of dropping the values, you can replace the values with a summary statistic or a specific value. You must be mindful of whether the data is continuous or discrete when making that determination. Here's an example using ```fillna()```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ef039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Let's try selecting any column that has a number and filling it with zeros. Try it with the mean! \n",
    "# Compare the two using the describe function. Do you see anything different? Also consider, \n",
    "# does it make sense based on the variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2058f",
   "metadata": {},
   "source": [
    "We can see that compared to earlier, all the NaN values for integers have been filled in. Now we'll drop any additional NaN values and see how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Drop the rest of the NaN values and take a look at the shape of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9ed3a",
   "metadata": {},
   "source": [
    "Now let's address duplicate values. We will be using the ```drop_duplicates()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1947e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Drop any duplicates. Does the shape change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e71312",
   "metadata": {},
   "source": [
    "During this stage, you can also rename your columns so that it will be easier to refer to them during data analysis or delete columns if they may not be relevant to your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4187ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Try renaming your columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ca089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Drop columns that you don't think you'll use for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925a482",
   "metadata": {},
   "source": [
    "## Enriching\n",
    "\n",
    "This dataset came with additional information regarding their previous credits provided by other financial institutions, their monthly balance snapshots of previous POS and cash loans that the applicant had with home credit, and their previous credit card balance. Let's see if we can merge two of the data sets given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8929b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import the bureau data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Merge both data sets using an inner joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e6371",
   "metadata": {},
   "source": [
    "Additionally, let's add a separate column which shows the percentage of children out of all the family members in the household."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Add a new column calculating the percentage of children who are family members in each household"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800652f4",
   "metadata": {},
   "source": [
    "## Validate\n",
    "\n",
    "We'll use this time to see if anything has changed dramatically within the data. To do this we'll take a look at the following:\n",
    "- Summary Statistics + Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: See how the data looks compared to when we last described the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae91aacf",
   "metadata": {},
   "source": [
    "- Spot Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f6e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Randomly sample 5 values and see how they look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f94682",
   "metadata": {},
   "source": [
    "- Missing Values Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec2dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Is there anything else missing in the data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29ae52",
   "metadata": {},
   "source": [
    "# Data Analysis/Visualization\n",
    "\n",
    "After we've cleaned the data, now we can work with the data. \n",
    "\n",
    "In Pandas, there are a series of summary statistics that can be calculated from your dataframe. You can either use the ```describe()``` function or the summary operators: ```mean()```, ```mode()```, or ```median()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e35701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Calculate the mean for each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853f3ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Calculate the mode for each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6371b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Calculate the median for each numeric column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dbaef4",
   "metadata": {},
   "source": [
    "You can also count the number of values within a categorical variable using the ```value_counts()``` function. Use normalize to return proportions instead of absolute counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db35f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Calculate the value counts for each numeric column. Try setting normalize equal to true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ea2842",
   "metadata": {},
   "source": [
    "Here, we're using the ```groupby()``` function. Remember in the merged table there were multiple duplicates for SK_ID_CURR due to the credit type that each individual had? This function helps to group those entries and take the mean of those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Let's use the merge table - clean the table up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Use the group by function to group the duplicate SK_ID_CURR together by their credit type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cb58a0",
   "metadata": {},
   "source": [
    "You can also create pivot tables with your summary statistics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Let's create a pivot table! We'll use values=\"AMT_CREDIT_SUM\", index='TARGET', and columns=['CREDIT_TYPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223479a3",
   "metadata": {},
   "source": [
    "Additionally, you can run correlations within your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc65b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Take a look at the correlation chart, do you see any highly correlating values? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d605a8",
   "metadata": {},
   "source": [
    "You can also map out your data using Pandas. Here we will create a series of graphs with our data, including a line graph, a bar chart, and a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e0e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create a line chart using the AMT_INCOME_TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e009ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create a bar chart using the NAME_CONTRACT_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create a box chart using the AMT_INCOME_TOTAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7853a15",
   "metadata": {},
   "source": [
    "# Additional Packages\n",
    "\n",
    "Pandas is powerful as is, but in conjunction with other packages, you will be able to do a lot more with the data given. Some of the popular packages include:\n",
    "- [NumPy for numerical computing](https://numpy.org/)\n",
    "- [Matplotlib](https://numpy.org/), [Seaborn](https://seaborn.pydata.org/) for visualizations\n",
    "- [scikit-learn](https://scikit-learn.org/stable/), [PyTorch](https://pytorch.org/) for machine learning\n",
    "\n",
    "If you're interested, click on each of the links to learn more!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd848ad",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44001621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[2, 3, 1],\n",
    "              [4, 6, 5]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac39a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "np.concatenate((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548991a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1 , 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "five_up = (a > 5) | (a == 5)\n",
    "print(five_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1, 2])\n",
    "ones = np.ones(2, dtype=int)\n",
    "\n",
    "data + ones\n",
    "data - ones\n",
    "data * data\n",
    "data / data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11499538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([1.0, 2.0])\n",
    "data * 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a54eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max()\n",
    "data.min()\n",
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "# Create a visualization\n",
    "sns.relplot(\n",
    "    data=tips,\n",
    "    x=\"total_bill\", y=\"tip\", col=\"time\",\n",
    "    hue=\"smoker\", style=\"smoker\", size=\"size\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips, x=\"total_bill\", y=\"tip\", col=\"time\", hue=\"smoker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=tips, x=\"total_bill\", col=\"time\", kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=tips, kind=\"bar\", x=\"day\", y=\"total_bill\", hue=\"smoker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1126d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(tips.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reg = LogisticRegression(random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                     df[['AMT_INCOME_TOTAL']], df['TARGET'], test_size=0.33, random_state=42)\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed127ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"presentation/application_test.csv\").fillna(0)\n",
    "\n",
    "reg.predict(df_test[['AMT_INCOME_TOTAL']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
